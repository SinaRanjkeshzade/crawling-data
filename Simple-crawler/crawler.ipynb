{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bee511a",
   "metadata": {},
   "source": [
    "# Simple crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee117e",
   "metadata": {},
   "source": [
    "# Installing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be9cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (2.32.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (4.13.4)\n",
      "Requirement already satisfied: markdownify in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: lxml in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (6.0.0)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: six<2,>=1.15 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from markdownify) (1.17.0)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Using cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sina/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m971.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-2.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]2m3/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed numpy-2.3.1 pandas-2.3.1 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 markdownify lxml pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b7339",
   "metadata": {},
   "source": [
    "# Understaning the HTML structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a92b85c",
   "metadata": {},
   "source": [
    "## Extracting html content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b18fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "url = 'https://quotes.toscrape.com/'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()\n",
    "with open(\"quotes.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783def94",
   "metadata": {},
   "source": [
    "## displaying HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c413840e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "\t<meta charset=\"UTF-8\">\n",
       "\t<title>Quotes to Scrape</title>\n",
       "    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n",
       "    <link rel=\"stylesheet\" href=\"/static/main.css\">\n",
       "    \n",
       "    \n",
       "</head>\n",
       "<body>\n",
       "    <div class=\"container\">\n",
       "        <div class=\"row header-box\">\n",
       "            <div class=\"col-md-8\">\n",
       "                <h1>\n",
       "                    <a href=\"/\" style=\"text-decoration: none\">Quotes to Scrape</a>\n",
       "                </h1>\n",
       "            </div>\n",
       "            <div class=\"col-md-4\">\n",
       "                <p>\n",
       "                \n",
       "                    <a href=\"/login\">Login</a>\n",
       "                \n",
       "                </p>\n",
       "            </div>\n",
       "        </div>\n",
       "    \n",
       "\n",
       "<div class=\"row\">\n",
       "    <div class=\"col-md-8\">\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"change,deep-thoughts,thinking,world\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/thinking/page/1/\">thinking</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/world/page/1/\">world</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“It is our choices, Harry, that show what we truly are, far more than our abilities.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\n",
       "        <a href=\"/author/J-K-Rowling\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"abilities,choices\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"inspirational,life,live,miracle,miracles\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/live/page/1/\">live</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/miracle/page/1/\">miracle</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/miracles/page/1/\">miracles</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Jane Austen</small>\n",
       "        <a href=\"/author/Jane-Austen\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"aliteracy,books,classic,humor\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/aliteracy/page/1/\">aliteracy</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/books/page/1/\">books</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/classic/page/1/\">classic</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“Imperfection is beauty, madness is genius and it&#39;s better to be absolutely ridiculous than absolutely boring.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Marilyn Monroe</small>\n",
       "        <a href=\"/author/Marilyn-Monroe\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"be-yourself,inspirational\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/be-yourself/page/1/\">be-yourself</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“Try not to become a man of success. Rather become a man of value.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n",
       "        <a href=\"/author/Albert-Einstein\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"adulthood,success,value\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/adulthood/page/1/\">adulthood</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/success/page/1/\">success</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/value/page/1/\">value</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“It is better to be hated for what you are than to be loved for what you are not.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">André Gide</small>\n",
       "        <a href=\"/author/Andre-Gide\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"life,love\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/life/page/1/\">life</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/love/page/1/\">love</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“I have not failed. I&#39;ve just found 10,000 ways that won&#39;t work.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Thomas A. Edison</small>\n",
       "        <a href=\"/author/Thomas-A-Edison\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"edison,failure,inspirational,paraphrased\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/edison/page/1/\">edison</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/failure/page/1/\">failure</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/inspirational/page/1/\">inspirational</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/paraphrased/page/1/\">paraphrased</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“A woman is like a tea bag; you never know how strong it is until it&#39;s in hot water.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Eleanor Roosevelt</small>\n",
       "        <a href=\"/author/Eleanor-Roosevelt\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"misattributed-eleanor-roosevelt\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/misattributed-eleanor-roosevelt/page/1/\">misattributed-eleanor-roosevelt</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <div class=\"quote\" itemscope itemtype=\"http://schema.org/CreativeWork\">\n",
       "        <span class=\"text\" itemprop=\"text\">“A day without sunshine is like, you know, night.”</span>\n",
       "        <span>by <small class=\"author\" itemprop=\"author\">Steve Martin</small>\n",
       "        <a href=\"/author/Steve-Martin\">(about)</a>\n",
       "        </span>\n",
       "        <div class=\"tags\">\n",
       "            Tags:\n",
       "            <meta class=\"keywords\" itemprop=\"keywords\" content=\"humor,obvious,simile\" /    > \n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/humor/page/1/\">humor</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/obvious/page/1/\">obvious</a>\n",
       "            \n",
       "            <a class=\"tag\" href=\"/tag/simile/page/1/\">simile</a>\n",
       "            \n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <nav>\n",
       "        <ul class=\"pager\">\n",
       "            \n",
       "            \n",
       "            <li class=\"next\">\n",
       "                <a href=\"/page/2/\">Next <span aria-hidden=\"true\">&rarr;</span></a>\n",
       "            </li>\n",
       "            \n",
       "        </ul>\n",
       "    </nav>\n",
       "    </div>\n",
       "    <div class=\"col-md-4 tags-box\">\n",
       "        \n",
       "            <h2>Top Ten tags</h2>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 28px\" href=\"/tag/love/\">love</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/inspirational/\">inspirational</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 26px\" href=\"/tag/life/\">life</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 24px\" href=\"/tag/humor/\">humor</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 22px\" href=\"/tag/books/\">books</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 14px\" href=\"/tag/reading/\">reading</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 10px\" href=\"/tag/friendship/\">friendship</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/friends/\">friends</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 8px\" href=\"/tag/truth/\">truth</a>\n",
       "            </span>\n",
       "            \n",
       "            <span class=\"tag-item\">\n",
       "            <a class=\"tag\" style=\"font-size: 6px\" href=\"/tag/simile/\">simile</a>\n",
       "            </span>\n",
       "            \n",
       "        \n",
       "    </div>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "    <footer class=\"footer\">\n",
       "        <div class=\"container\">\n",
       "            <p class=\"text-muted\">\n",
       "                Quotes by: <a href=\"https://www.goodreads.com/quotes\">GoodReads.com</a>\n",
       "            </p>\n",
       "            <p class=\"copyright\">\n",
       "                Made with <span class='zyte'>❤</span> by <a class='zyte' href=\"https://www.zyte.com\">Zyte</a>\n",
       "            </p>\n",
       "        </div>\n",
       "    </footer>\n",
       "</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123c448",
   "metadata": {},
   "source": [
    "## Convert HTML to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b74aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdownify import markdownify as md\n",
    "md_content = md(response.text)\n",
    "with open(\"quotes.md\", \"w\", encoding='utf-8') as f:\n",
    "    f.write(md_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79a200",
   "metadata": {},
   "source": [
    "# Parsing HTML with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd837948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c264d5",
   "metadata": {},
   "source": [
    "## Extract all links from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae67a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "links = []\n",
    "for a in soup.find_all('a', href=True):\n",
    "    link_text = a.get_text(strip=True)\n",
    "    link_url = a['href']\n",
    "    links.append({'text': link_text, 'url': link_url})\n",
    "with open(\"links.json\", \"w\") as f:\n",
    "    json.dump(links, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "## extract absolute urls\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "absolute_links = []\n",
    "base_url = response.url if hasattr(response, 'url') else \"https://quotes.toscrape.com/\"\n",
    "for a in soup.find_all('a', href=True):\n",
    "    link_text = a.get_text(strip=True)\n",
    "    link_url = urljoin(base_url, a['href'])\n",
    "    absolute_links.append({'text': link_text, 'url': link_url})\n",
    "with open(\"links_absolute.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(absolute_links, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b968760",
   "metadata": {},
   "source": [
    "## Extracting quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2739174",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_data = []\n",
    "for quote_div in soup.find_all(\"div\", class_=\"quote\"):\n",
    "    # Extract quote text\n",
    "    text_span = quote_div.find(\"span\", class_=\"text\")\n",
    "    quote_text = text_span.get_text(strip=True) if text_span else \"\"\n",
    "    # Extract author\n",
    "    author_small = quote_div.find(\"small\", class_=\"author\")\n",
    "    author = author_small.get_text(strip=True) if author_small else \"\"\n",
    "    # Extract tags\n",
    "    tags_div = quote_div.find(\"div\", class_=\"tags\")\n",
    "    tags = []\n",
    "    if tags_div:\n",
    "        tags = [a.get_text(strip=True) for a in tags_div.find_all(\"a\", class_=\"tag\")]\n",
    "    quotes_data.append({\n",
    "        \"text\": quote_text,\n",
    "        \"author\": author,\n",
    "        \"tags\": tags\n",
    "    })\n",
    "\n",
    "with open(\"quotes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(quotes_data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de9f71",
   "metadata": {},
   "source": [
    "## Extract the Top ten tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68585daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"Top Ten tags\" box in the HTML and extract the tags and their URLs\n",
    "top_ten_tags = []\n",
    "tags_box = soup.find(\"div\", class_=\"tags-box\")\n",
    "if tags_box:\n",
    "    for tag_item in tags_box.find_all(\"span\", class_=\"tag-item\"):\n",
    "        tag_a = tag_item.find(\"a\", class_=\"tag\")\n",
    "        if tag_a:\n",
    "            tag_text = tag_a.get_text(strip=True)\n",
    "            tag_url = tag_a[\"href\"]\n",
    "            top_ten_tags.append({\"tag\": tag_text, \"url\": tag_url})\n",
    "\n",
    "with open(\"top_ten_tags.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(top_ten_tags, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a88ec2",
   "metadata": {},
   "source": [
    "# Parsing by beautifulsoap in lxml mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a44b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "soup = BeautifulSoup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40914416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract quotes, authors, and tags using lxml parser\n",
    "quotes_data_lxml = []\n",
    "quotes_lxml = soup.find_all(\"div\", class_=\"quote\")\n",
    "for quote in quotes_lxml:\n",
    "    quote_text = quote.find(\"span\", class_=\"text\")\n",
    "    author = quote.find(\"small\", class_=\"author\")\n",
    "    tags_div = quote.find(\"div\", class_=\"tags\")\n",
    "    text = quote_text.get_text(strip=True) if quote_text else \"\"\n",
    "    author_name = author.get_text(strip=True) if author else \"\"\n",
    "    tags = []\n",
    "    if tags_div:\n",
    "        tags = [a.get_text(strip=True) for a in tags_div.find_all(\"a\", class_=\"tag\")]\n",
    "    quotes_data_lxml.append({\n",
    "        \"text\": text,\n",
    "        \"author\": author_name,\n",
    "        \"tags\": tags\n",
    "    })\n",
    "\n",
    "# Extract top ten tags using lxml parser\n",
    "top_ten_tags_lxml = []\n",
    "tags_box_lxml = soup.find(\"div\", class_=\"tags-box\")\n",
    "if tags_box_lxml:\n",
    "    for tag_item in tags_box_lxml.find_all(\"span\", class_=\"tag-item\"):\n",
    "        tag_a = tag_item.find(\"a\", class_=\"tag\")\n",
    "        if tag_a:\n",
    "            tag_text = tag_a.get_text(strip=True)\n",
    "            tag_url = tag_a[\"href\"]\n",
    "            top_ten_tags_lxml.append({\"tag\": tag_text, \"url\": tag_url})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d090232",
   "metadata": {},
   "source": [
    "# Working with css selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90c25ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "“A day without sunshine is like, you know, night.”\n"
     ]
    }
   ],
   "source": [
    "quotes = soup.select('div.quote span.text')\n",
    "for quote in quotes:\n",
    "    print(quote.get_text(strip=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc4199",
   "metadata": {},
   "source": [
    "# Working with XPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680972df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "“A day without sunshine is like, you know, night.”\n"
     ]
    }
   ],
   "source": [
    "from lxml import html\n",
    "tree = html.fromstring(response.text)\n",
    "quotes = tree.xpath('//div[@class=\"quote\"]/span[@class=\"text\"]/text()')\n",
    "for quote in quotes:\n",
    "    print(quote.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50915983",
   "metadata": {},
   "source": [
    "# Crawling whole website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1abb4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"http://quotes.toscrape.com\"\n",
    "all_quotes = []\n",
    "\n",
    "next_page_url = \"/\"\n",
    "while next_page_url:\n",
    "    url = base_url + next_page_url\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    quotes = soup.find_all(\"div\", class_=\"quote\")\n",
    "    for quote in quotes:\n",
    "        text = quote.find(\"span\", class_=\"text\").get_text(strip=True)\n",
    "        author = quote.find(\"small\", class_=\"author\").get_text(strip=True)\n",
    "        tags = [tag.get_text(strip=True) for tag in quote.find_all(\"a\", class_=\"tag\")]\n",
    "        all_quotes.append({\n",
    "            \"text\": text,\n",
    "            \"author\": author,\n",
    "            \"tags\": tags\n",
    "        })\n",
    "    next_btn = soup.find(\"li\", class_=\"next\")\n",
    "    if next_btn and next_btn.a:\n",
    "        next_page_url = next_btn.a[\"href\"]\n",
    "    else:\n",
    "        next_page_url = None\n",
    "\n",
    "# Save the number of quotes and a sample to files\n",
    "import json\n",
    "\n",
    "with open(\"all_quotes.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_quotes, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba5922a",
   "metadata": {},
   "source": [
    "# Crawling quotes website without using the 'more' or 'next' buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "492902e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 found in page 1\n",
      "10 found in page 2\n",
      "10 found in page 3\n",
      "10 found in page 4\n",
      "10 found in page 5\n",
      "10 found in page 6\n",
      "10 found in page 7\n",
      "10 found in page 8\n",
      "10 found in page 9\n",
      "10 found in page 10\n",
      "0 found in page 11\n",
      "0 found in page 12\n",
      "0 found in page 13\n",
      "0 found in page 14\n",
      "0 found in page 15\n",
      "0 found in page 16\n",
      "0 found in page 17\n",
      "0 found in page 18\n",
      "0 found in page 19\n",
      "0 found in page 20\n",
      "0 found in page 21\n",
      "0 found in page 22\n",
      "0 found in page 23\n",
      "0 found in page 24\n",
      "0 found in page 25\n",
      "0 found in page 26\n",
      "0 found in page 27\n",
      "0 found in page 28\n",
      "0 found in page 29\n",
      "0 found in page 30\n",
      "0 found in page 31\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m page = \u001b[32m1\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m404\u001b[39m:\n\u001b[32m      9\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/hamrah-academy/crawling data webinar/.venv/lib/python3.11/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/http/client.py:1374\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1373\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1375\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1376\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/http/client.py:318\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/http/client.py:279\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/socket.py:705\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    704\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    707\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/ssl.py:1278\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1275\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1276\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1277\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1278\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/ssl.py:1134\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1134\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://quotes.toscrape.com/page/\"\n",
    "page = 1\n",
    "while True:\n",
    "    response = requests.get(f\"{base_url}{page}/\")\n",
    "    if response.status_code == 404:\n",
    "        break\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    quotes = soup.select('div.quote span.text')\n",
    "    num_quotes = 0\n",
    "    for quote in quotes:\n",
    "        num_quotes += 1\n",
    "\n",
    "    print(f\"{num_quotes} found in page {page}\")\n",
    "    page += 1\n",
    "\n",
    "print(f\"# Pages: {page}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f37dc46",
   "metadata": {},
   "source": [
    "# Crawling hackernews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f6b9db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "robots.txt:\n",
      " User-Agent: *\n",
      "Crawl-delay: 30\n",
      "Disallow: /collapse?\n",
      "Disallow: /context?\n",
      "Disallow: /fave?\n",
      "Disallow: /flag?\n",
      "Disallow: /hide?\n",
      "Disallow: /login\n",
      "Disallow: /logout\n",
      "Disallow: /r?\n",
      "Disallow: /reply?\n",
      "Disallow: /submitlink?\n",
      "Disallow: /vote?\n",
      "Disallow: /x?\n",
      "\n",
      "Crawled 900 stories from Hacker News.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import time\n",
    "\n",
    "# Check robots.txt for allowed paths\n",
    "robots_url = \"https://news.ycombinator.com/robots.txt\"\n",
    "robots_txt = requests.get(robots_url).text\n",
    "print(\"robots.txt:\\n\", robots_txt)\n",
    "\n",
    "# According to robots.txt, crawling \"/\" is allowed for all user-agents.\n",
    "\n",
    "base_url = \"https://news.ycombinator.com/\"\n",
    "page_url = base_url\n",
    "all_stories = []\n",
    "max_pages = 30  # Limit to 3 pages to avoid overloading\n",
    "\n",
    "for i in range(max_pages):\n",
    "    resp = requests.get(page_url)\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "    rows = soup.find_all(\"tr\", class_=\"athing\")\n",
    "    for row in rows:\n",
    "        title = row.find(\"a\", class_=\"storylink\")\n",
    "        if not title:\n",
    "            title = row.find(\"span\", class_=\"titleline\")\n",
    "            if title:\n",
    "                title = title.find(\"a\")\n",
    "        story = {\n",
    "            \"title\": title.get_text(strip=True) if title else \"\",\n",
    "            \"url\": title[\"href\"] if title and title.has_attr(\"href\") else \"\",\n",
    "            \"id\": row.get(\"id\")\n",
    "        }\n",
    "        all_stories.append(story)\n",
    "    # Find \"More\" link for next page\n",
    "    more = soup.find(\"a\", string=\"More\")\n",
    "    if more and more.has_attr(\"href\"):\n",
    "        page_url = urljoin(base_url, more[\"href\"])\n",
    "        time.sleep(1)  # Be polite\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Save results\n",
    "with open(\"hackernews_stories.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_stories, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Crawled {len(all_stories)} stories from Hacker News.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942a7047",
   "metadata": {},
   "source": [
    "# Introducing re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4de8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 stories with purely numeric IDs.\n",
      "Found 6 stories with 'Python' in the title.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Example: Extract all story IDs that are purely numeric using re from the crawled data\n",
    "with open(\"hackernews_stories.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    stories = json.load(f)\n",
    "\n",
    "numeric_id_stories = []\n",
    "for story in stories:\n",
    "    if story[\"id\"] and re.fullmatch(r\"\\d+\", story[\"id\"]):\n",
    "        numeric_id_stories.append(story)\n",
    "\n",
    "print(f\"Found {len(numeric_id_stories)} stories with purely numeric IDs.\")\n",
    "\n",
    "# Example: Find all stories whose title contains the word 'Python' (case-insensitive)\n",
    "python_stories = [s for s in stories if re.search(r\"\\bpython\\b\", s[\"title\"], re.IGNORECASE)]\n",
    "print(f\"Found {len(python_stories)} stories with 'Python' in the title.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d12f99",
   "metadata": {},
   "source": [
    "# Conversion to proper data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5d4f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text           author  \\\n",
      "0  “The world as we have created it is a process ...  Albert Einstein   \n",
      "1  “It is our choices, Harry, that show what we t...     J.K. Rowling   \n",
      "2  “There are only two ways to live your life. On...  Albert Einstein   \n",
      "3  “The person, be it gentleman or lady, who has ...      Jane Austen   \n",
      "4  “Imperfection is beauty, madness is genius and...   Marilyn Monroe   \n",
      "\n",
      "                                             tags  \n",
      "0        [change, deep-thoughts, thinking, world]  \n",
      "1                            [abilities, choices]  \n",
      "2  [inspirational, life, live, miracle, miracles]  \n",
      "3              [aliteracy, books, classic, humor]  \n",
      "4                    [be-yourself, inspirational]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the crawled data from the quotes website\n",
    "with open(\"all_quotes.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    quotes_data = json.load(f)\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "quotes_df = pd.DataFrame(quotes_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(quotes_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc007456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_205877/1914720808.py:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  quotes_df_clean = quotes_df.applymap(list_to_str)\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame to a SQLite database\n",
    "import sqlite3\n",
    "\n",
    "# Convert any columns containing lists to strings (e.g., join lists with commas)\n",
    "import numpy as np\n",
    "\n",
    "def list_to_str(val):\n",
    "    if isinstance(val, list):\n",
    "        return \", \".join(str(x) for x in val)\n",
    "    return val\n",
    "\n",
    "quotes_df_clean = quotes_df.applymap(list_to_str)\n",
    "\n",
    "# Create a connection to a new SQLite database (or connect if it exists)\n",
    "conn = sqlite3.connect(\"quotes.db\")\n",
    "\n",
    "# Save the cleaned DataFrame to the SQLite database in a table named 'quotes'\n",
    "quotes_df_clean.to_sql(\"quotes\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "quotes_df_clean.to_csv(\"quotes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcc302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
